# TASK-15, TASK-16, TASK-17 Documentation

## Overview

This document describes the implementation of:
- **TASK-15**: Queue Producer (Rule-Based → Queue)
- **TASK-16**: Request Status Tracking Store
- **TASK-17**: Confidence Calibration

## TASK-15: Queue Producer

### Description
Publishes ambiguous queries from rule-based classification to the intent classification queue for asynchronous LLM processing.

### Implementation
- **File**: `app/queue/queue_producer.py`
- **Technology**: Redis (adapted from RabbitMQ implementation in CNS-22)
- **Message Format**: Matches TASK-15 specification exactly

### Usage

```python
from app.queue.queue_producer import get_queue_producer

producer = get_queue_producer()

# Publish ambiguous query
request_id = producer.publish_ambiguous_query(
    query="I need something for running",
    rule_based_result={
        "action_code": "UNCLEAR",
        "confidence": 0.35,
        "matched_keywords": []
    },
    user_id="user_123",
    session_id="session_456",
    conversation_history=[],
    priority="normal"  # or "high"
)

print(f"Request ID: {request_id}")
```

### Message Format
```json
{
    "request_id": "uuid-v4",
    "user_query": "I need something for running",
    "session_id": "session-123",
    "user_id": "user-456",
    "conversation_history": [],
    "rule_based_result": {
        "action_code": "UNCLEAR",
        "confidence": 0.45,
        "matched_keywords": []
    },
    "timestamp": "2025-10-19T10:30:00Z",
    "priority": "normal",
    "metadata": {}
}
```

### Features
- ✅ UUID v4 request_id generation
- ✅ Batching support (configurable)
- ✅ Idempotency checking
- ✅ Priority messages (normal/high)
- ✅ Error handling and logging
- ✅ Integration with Status Store (creates QUEUED status)

### API Integration
The producer is automatically used by:
- `app/ai/intent_classification/decision_engine.py` - Routes ambiguous queries to queue
- `app/queue/integration.py` - `send_to_llm_queue()` function

---

## TASK-16: Request Status Tracking Store

### Description
Fast key-value store to track the status of classification requests for client polling or webhooks.

### Implementation
- **Files**: 
  - `app/core/status_store.py` - Redis and in-memory implementations
  - `app/schemas/request_status.py` - Pydantic schemas
- **Technology**: Redis with in-memory fallback
- **Performance**: <10ms p95 lookup time

### Usage

```python
from app.core.status_store import status_store
from app.schemas.request_status import RequestStatus, ResultSchema
from datetime import datetime, timezone

# Create QUEUED status
request_id = "uuid-v4"
status = RequestStatus(
    request_id=request_id,
    status="QUEUED",
    queued_at=datetime.now(timezone.utc)
)
status_store.save(status)

# Update to PROCESSING
status_store.update_status(request_id, "PROCESSING")

# Complete with result
result = ResultSchema(
    action_code="SEARCH",
    confidence=0.87,
    entities={"query": "running shoes"}
)
status_store.complete_request(request_id, result=result)

# Retrieve status
status = status_store.get(request_id)
print(f"Status: {status.status}")
print(f"Result: {status.result.action_code}")
```

### Status Lifecycle
1. **QUEUED** - Request entered queue (`queued_at` timestamp)
2. **PROCESSING** - Worker started processing (`started_at` timestamp)
3. **COMPLETED** - Processing finished successfully (`completed_at` timestamp, `result` field)
4. **FAILED** - Processing failed (`completed_at` timestamp, `error` field)

### API Endpoint

```
GET /api/v1/queue/status/{request_id}
```

**Response**:
```json
{
    "request_id": "uuid-v4",
    "status": "COMPLETED",
    "queued_at": "2025-10-19T10:30:00Z",
    "started_at": "2025-10-19T10:30:01Z",
    "completed_at": "2025-10-19T10:30:03Z",
    "result": {
        "action_code": "SEARCH",
        "confidence": 0.87,
        "entities": {"query": "running shoes"}
    },
    "error": null,
    "retry_count": 0
}
```

### Features
- ✅ Fast Redis-based storage (<10ms p95 lookup)
- ✅ Automatic expiration (1 hour for completed/failed, 24 hours for queued/processing)
- ✅ In-memory fallback when Redis unavailable
- ✅ Full status lifecycle tracking
- ✅ Error details storage
- ✅ Retry count tracking

### Integration
- **Queue Producer**: Creates QUEUED status on publish
- **Queue Worker**: Updates to PROCESSING → COMPLETED/FAILED
- **API Endpoint**: Provides status polling

---

## TASK-17: Confidence Calibration

### Description
System to calibrate and validate confidence scores returned by the LLM based on historical accuracy.

### Implementation
- **File**: `app/ai/llm_intent/confidence_calibration.py`
- **Technology**: Redis for historical tracking (with in-memory fallback)

### Usage

```python
from app.ai.llm_intent.confidence_calibration import get_calibrator, get_tracker

calibrator = get_calibrator()
tracker = get_tracker()

# Calibrate confidence score
reported_confidence = 0.75
calibrated_confidence = calibrator.calibrate_confidence(
    action_code="SEARCH",
    reported_confidence=reported_confidence
)
print(f"Original: {reported_confidence:.2f} → Calibrated: {calibrated_confidence:.2f}")

# Record actual outcome for calibration
tracker.record_prediction(
    action_code="SEARCH",
    reported_confidence=reported_confidence,
    actual_outcome=True,  # True if prediction was correct
    request_id="uuid-v4"
)

# Get calibration statistics
stats = tracker.get_calibration_stats(action_code="SEARCH", min_samples=50)
if stats:
    print(f"Accuracy: {stats['overall_accuracy']:.2f}")
    print(f"Calibration error: {stats['calibration_error']:.2f}")
```

### Calibration Logic
1. **Historical Tracking**: Stores actual outcomes vs. reported confidence
2. **Bin-based Calibration**: Groups predictions into confidence bins (0.0-0.2, 0.2-0.4, etc.)
3. **Accuracy-based Adjustment**: Adjusts confidence to match observed accuracy in each bin
4. **Global Adjustment**: Applies overall calibration correction if error > 0.1

### Fallback Logic

```python
should_fallback, reason = calibrator.should_trigger_fallback(
    action_code="SEARCH",
    calibrated_confidence=0.3,
    fallback_threshold=0.5
)

if should_fallback:
    print(f"Trigger fallback: {reason}")
    # Use rule-based fallback, ask clarification, etc.
```

### Features
- ✅ Historical accuracy tracking (Redis-based, 90-day retention)
- ✅ Bin-based confidence calibration
- ✅ Per-action-code calibration
- ✅ Global calibration statistics
- ✅ Fallback logic for low-confidence responses
- ✅ Threshold adjustment based on observed performance

### Integration
- **Queue Worker**: Automatically calibrates confidence before storing results
- **Status Store**: Stores calibrated confidence scores
- **Monitoring**: Tracks calibration accuracy over time

---

## End-to-End Flow

### Complete Request Flow

1. **User Query** → Decision Engine detects ambiguity
2. **Queue Producer** → Publishes to queue, creates QUEUED status
3. **Queue Worker** → Dequeues message, updates to PROCESSING
4. **LLM Processing** → Processes with GPT-4
5. **Calibration** → Adjusts confidence based on historical accuracy
6. **Status Store** → Updates to COMPLETED with calibrated result
7. **Client Polling** → GET `/api/v1/queue/status/{request_id}` returns result

### Example Flow

```python
# 1. Publish ambiguous query
from app.queue.queue_producer import get_queue_producer
producer = get_queue_producer()

request_id = producer.publish_ambiguous_query(
    query="I want to buy something",
    rule_based_result={"action_code": "UNCLEAR", "confidence": 0.3},
    user_id="user_123"
)

# 2. Poll for status (client-side)
from app.core.status_store import status_store
import time

while True:
    status = status_store.get(request_id)
    if status:
        if status.status == "COMPLETED":
            print(f"Result: {status.result.action_code}")
            print(f"Confidence: {status.result.confidence:.2f}")
            break
        elif status.status == "FAILED":
            print(f"Error: {status.error}")
            break
    time.sleep(0.5)  # Poll every 500ms
```

---

## Configuration

### Environment Variables

```bash
# Redis (required for production)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# Queue Configuration
ENABLE_LLM_QUEUE=true  # Enable/disable queue-based processing
```

### Queue Producer Configuration

```python
producer = IntentQueueProducer({
    "batch_size": 1,  # Messages per batch
    "batch_timeout": 60.0,  # Seconds before flushing batch
    "enable_idempotency": True,  # Enable duplicate detection
    "idempotency_ttl": 300  # Idempotency TTL in seconds
})
```

---

## Testing

### Unit Tests
```bash
# Status Store tests
pytest tests/intent_classification_tests/status_store/test_status_store.py -v

# Integration tests
pytest tests/integration/test_tasks_15_16_17_integration.py -v
```

### Manual Testing
```python
# Test queue producer
python3 -c "from app.queue.queue_producer import get_queue_producer; print('OK')"

# Test status store
python3 -c "from app.core.status_store import status_store; print('OK')"

# Test calibration
python3 -c "from app.ai.llm_intent.confidence_calibration import get_calibrator; print('OK')"
```

---

## Troubleshooting

### Status Store Returns None
- Check Redis connection: `redis-cli ping`
- Check if using in-memory fallback (logs will show warning)
- Verify request_id exists in Redis: `redis-cli KEYS "chatns:status:*"`

### Queue Producer Fails
- Check Redis is running
- Verify queue manager is available: `GET /api/v1/queue/health`
- Check logs for connection errors

### Calibration Not Adjusting Scores
- Ensure historical data exists (minimum 50 samples per action_code)
- Check Redis keys: `redis-cli KEYS "chatns:calibration:*"`
- Verify calibration is called in worker (check logs)

---

## Performance Metrics

### TASK-16 Requirements
- ✅ Fast lookup: <10ms p95 (Redis: typically <1ms)
- ✅ Automatic expiration: 1 hour for completed/failed
- ✅ Status tracking: QUEUED → PROCESSING → COMPLETED/FAILED

### TASK-17 Requirements
- ✅ Historical tracking: 90-day retention
- ✅ Calibration accuracy: Adjusts based on observed performance
- ✅ Fallback logic: Triggers on low confidence

---

## Future Enhancements

1. **Webhook Support**: Push status updates to webhooks instead of polling
2. **Batch Processing**: Optimize batch size based on load
3. **Calibration Dashboard**: Visualize calibration accuracy over time
4. **A/B Testing**: Test different calibration strategies
5. **Multi-region**: Support Redis replication for high availability

